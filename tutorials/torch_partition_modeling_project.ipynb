{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('th-federated': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c2ea6ed944d6425ee8782cf654adb8ea89a16b622c320e18cab62be437316a17"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from easydict import EasyDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import (\n",
    "    DataLoader\n",
    "    , Dataset\n",
    "    , SubsetRandomSampler\n",
    ")"
   ]
  },
  {
   "source": [
    "# Modularity in Deep Learning Projects\n",
    "\n",
    "To make our code more understandable, we'd better decompose our huge blobs of modeling program into a collection smaller and easy-to-read code files. Further, we can organize these smaller pieces of code files into several categories, namely: \n",
    "\n",
    "* Data Loader\n",
    "* Graphs\n",
    "    + Models\n",
    "    + Loss Layers\n",
    "* Utils\n",
    "* Config\n",
    "\n",
    "To piece these seperate components together, we use the so-called **Agents**. In plain English or Computer Science Terminologies: main function (actually the main \"object\" instead of a function, explained later). To conduct experiments, we simply instantiate the corresponding Agent in a driver function and call the corresponding methods of our Agent.\n",
    "\n",
    "In short, we are able to sort out the dependencies between code files in a hiearchical mannar that reduces the difficulties for others to approach our project. This is **NOT** my novel idea. The project template I deem really satisfying can be found [here](https://github.com/moemen95/PyTorch-Project-Template#tutorials) (please give them a star :D). \n",
    "\n",
    "Although their GitHub Repo already contains everything that thoroughly explain the idea mentioned above, the code files are scattered in their own folders, making referencing files back and forth annoying. In this tutorial, I will try to give a vanilla version and put all of the modules in a single file (note that some of the features may get lost). The modeling project in this notebook is a *Binary Classification* problem using *Logistic Regression* model based on the *Breast Cancer* dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data Loader\n",
    "\n",
    "Generally speaking, the Data Loaders convert raw data files, no matter the fomat, into tensors for training. For `PyTorch` projects, we'd better learner to use `DataLoader` and `Dataset` abstractions to help us organize the datasets. A more detailed introduction regarding these two objects are introduced in another tutorial. \n",
    "\n",
    "In a word, we use `Dataset` to read in the raw data file and convert them into *a set of Records*, e.g. a pair of predictors and corresponding target stored in a tuple. And we define how we can slice the dataset. `DataLoader` are then created based on a certain dataset, and it gives us a uniform interface to access and operate the underlying dataset during the training session.\n",
    "\n",
    "So the general workflow is to instantiate a `DataLoader`, and, during the instantiation, it (1) creates a `Dataset` object, (2) shuffles the dataset, (3) \"splits\" the set according to certain configuration, and (4) defines iteration scheme, such as batch size. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreastCancerDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path):\n",
    "\n",
    "        # Let's just use pandas to read csv data\n",
    "        self.df = pd.read_csv(\n",
    "            path\n",
    "            , header=None  # This file contains no header\n",
    "            , index_col=0  # First column is an index column \n",
    "        ).replace({\n",
    "\n",
    "            # Recode the targets such that:\n",
    "            #   M(alignant) == 1\n",
    "            #   B(enign) == 0\n",
    "            1: {'M': 1, 'B': 0}  # 1 denote the second column\n",
    "        })\n",
    "\n",
    "        # Split X, Y and convert to tensors\n",
    "        self.factor = torch.tensor(\n",
    "            self.df.iloc[:, 1:].values, dtype=torch.float\n",
    "        )\n",
    "        self.target = torch.tensor(\n",
    "            self.df.iloc[:, :1].values, dtype=torch.float\n",
    "        )\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        # Return # target\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Return a tuple with the first element being the predictors\n",
    "        return self.factor[idx], self.target[idx]\n",
    "\n",
    "\n",
    "class BreastCancerDataLoader(object):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = EasyDict(config)\n",
    "\n",
    "        # Load data\n",
    "        self.dataset = BreastCancerDataset(\n",
    "            os.path.join(self.config.path_dir, self.config.path_file)\n",
    "        )\n",
    "\n",
    "        # Split train test, possibly dev set\n",
    "        #   1. Create indices\n",
    "        #   2. Make samplers\n",
    "        #   3. Create seperate data loaders, feeding both the datset and sampler\n",
    "        n_sample = len(self.dataset)\n",
    "        cut_train = int(self.config.pct_train * n_sample)\n",
    "        idxs_full = np.arange(n_sample)[torch.randperm(n_sample)]  # Shuffle\n",
    "\n",
    "        self.idxs_train = idxs_full[:cut_train]\n",
    "        self.idxs_valid = idxs_full[cut_train:]\n",
    "\n",
    "        splr_train = SubsetRandomSampler(self.idxs_train)\n",
    "        splr_valid = SubsetRandomSampler(self.idxs_valid)\n",
    "\n",
    "        self.loader_train = DataLoader(\n",
    "            self.dataset\n",
    "            , sampler=splr_train\n",
    "            , batch_size=self.config.batch_size\n",
    "        )\n",
    "        self.loader_valid = DataLoader(\n",
    "            self.dataset\n",
    "            , sampler=splr_valid\n",
    "            , batch_size=self.config.batch_size\n",
    "        )\n",
    "        return\n",
    "\n",
    "    def finalize(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Usually called at the end of the model training, basically save \n",
    "              all the dataset partition schemes to ensure repeatable experiments.\n",
    "              Not Implemented Here\n",
    "        \"\"\"\n",
    "\n",
    "        pass"
   ]
  },
  {
   "source": [
    "## Graph: Model and Loss Function\n",
    "\n",
    "For this simple demo, the logistic regression, we don't really need a self-defined loss function. We simply instantiate the `BCELoss` object. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        PyTorch implementation of Logistic Regression Model. \n",
    "          The predicted values (output of `self.forward(..)`)\n",
    "          are probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.linear = nn.Linear(\n",
    "            self.config.n_factor\n",
    "            , out_features=1\n",
    "            , bias=True\n",
    "        )\n",
    "        return\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        linear = self.linear(x)\n",
    "        return torch.sigmoid(linear)\n",
    "\n",
    "\n",
    "class BCELoss(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.loss_fn = nn.BCELoss(reduce=\"mean\")  # <-- average batch loss\n",
    "        return\n",
    "\n",
    "    def __call__(self, pred, target):\n",
    "\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Any object with `__call__` method implemented can\n",
    "              act like a function. In this case, our loss function \n",
    "              is called by: `fun = BCELoss; fun(...)`\n",
    "        \"\"\"\n",
    "\n",
    "        return self.loss_fn(pred, target)"
   ]
  },
  {
   "source": [
    "## Combines Everything: Agent\n",
    "\n",
    "The reason why we want to use an agent is that (1) we want to hide all the (ugly) details of our model, only exposing nice and clean interface, and (2) making the actual main function very short. The second advantage is essential for building a command line interface. In the main file, the code can focus on parsing all sorts of argument or deal with the runtime environment variables. It also makes switching from one model training instruction to another easily."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreastCancerLRAgent(BaseAgent):\n",
    "\n",
    "    def __init__(self, config: EasyDict):\n",
    "        self.config = config\n",
    "\n",
    "        # Model Init\n",
    "        self.loader = BreastCancerDataLoader(self.config.data)\n",
    "        self.model = LogisticRegression(self.config.model)\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        self.optimizer = torch.optim.SGD(\n",
    "            self.model.parameters()\n",
    "            , lr=self.config.train.lr\n",
    "        )\n",
    "\n",
    "        # Counter Init\n",
    "        self.cur_epoch = 0\n",
    "        self.cur_iter = 0\n",
    "        return\n",
    "\n",
    "    def load_checkpoint(self, path_checkpoint):\n",
    "\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Check point loader, very useful if training a HUGE model and \n",
    "              some exception happened. Not necessarily this implementation.\n",
    "        \"\"\"\n",
    "\n",
    "        checkpoint = torch.load(path_checkpoint)\n",
    "\n",
    "        self.model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "        self.cur_epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "        return True\n",
    "\n",
    "    def save_checkpoint(self, path_checkpoint):\n",
    "\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Same as stated above.\n",
    "        \"\"\"\n",
    "\n",
    "        checkpoint = {\n",
    "            \"epoch\": self.cur_epoch\n",
    "            , \"model_state\": self.model.state_dict()\n",
    "            , \"optimizer_state\": self.optimizer.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, path_checkpoint)\n",
    "\n",
    "        return True\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            The entry, like the `main(...)` function. In the main \n",
    "              function, we simply call this method with one line of code.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            self.train()\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"[ INFO. ] :: Keyboard Interruption, session ends\")\n",
    "        return\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            The main worker function that drive the training session.\n",
    "        \"\"\"\n",
    "        for _ in range(self.config.train.max_epoch):\n",
    "            self.cur_epoch += 1\n",
    "            self.train_one_epoch()\n",
    "            self.validate()\n",
    "        return\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Helper function of `self.train(...)`. One epoch of training.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.train()\n",
    "        self.cur_iter = 0\n",
    "\n",
    "        for batch_x, batch_y in self.loader.loader_train:\n",
    "            self.cur_iter += 1\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            pred = self.model.forward(batch_x)\n",
    "            loss_val = self.loss_fn(pred, batch_y)\n",
    "            loss_val.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if self.cur_iter % self.config.train.log_interval == 0:\n",
    "                print(\n",
    "                    \"[ TRAIN ] :: Epoch: {:}\\tBatch: {:}\\tBatch Train Loss: {:.6f}\".format(\n",
    "                        self.cur_epoch, self.cur_iter, loss_val.item()\n",
    "                    )\n",
    "                )\n",
    "        return\n",
    "\n",
    "    def validate(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            One cycle of model validation; iterate through all validation \n",
    "              samples and calculate (mean) loss\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        loss_val, n_batch = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in self.loader.loader_valid:\n",
    "                n_batch += 1\n",
    "                pred = self.model.forward(batch_x)\n",
    "                loss_val += self.loss_fn(pred, batch_y).item()\n",
    "        print(\n",
    "            \"[ VALID ] :: Epoch: {:}\\tBCE Loss: {:.6f}\".format(\n",
    "                self.cur_epoch, loss_val / n_batch\n",
    "            )\n",
    "        )\n",
    "        return\n",
    "\n",
    "    def finalize(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Finalizes all the operations of the 2 \n",
    "              Main classes of the process, the operator and the data loader\n",
    "        \"\"\"\n",
    "\n",
    "        path = os.path.join(self.config.io.path_dir, self.config.io.path_final)\n",
    "        self.save_checkpoint(path)\n",
    "        self.loader.finalize()\n",
    "\n",
    "        return True"
   ]
  },
  {
   "source": [
    "## Portable Code: A Config File\n",
    "\n",
    "As you may have noticed in the agent code above, I use the (Easy) Dictionary to pass the configuration of either dataloader or training sessions around. This design significantly reduces the difficulty of \"transplanting\" the program. We will see this advantage clearly when working with federated learning using `flwr` package. Note that the config files are usually stored in a seperate file. Personally I prefer `.toml` file. The grammar is very easy to understand and the `toml` package can help you load a toml file and convert it into a python dictionary directly."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"data\": {\n",
    "        \"path_dir\": \"../data/classification/breast_cancer\"\n",
    "        , \"path_file\": \"data.csv\"\n",
    "        , \"pct_train\": 0.7\n",
    "        , \"batch_size\": 4\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"n_factor\": 30\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"max_epoch\": 20\n",
    "        , \"lr\": 0.05\n",
    "    },\n",
    "    \"io\": {\n",
    "        \"path_dir\": None\n",
    "        , \"path_checkpoint\": None\n",
    "        , \"path_final\": None\n",
    "    }\n",
    "}"
   ]
  },
  {
   "source": [
    "## Finally, A Main Function\n",
    "\n",
    "To be honest, this is just a toy example. It only shows how simple a main function can be after we have partitioned the modeling code into pieces and keep them well-organized. The main purpose here is to ephasize the fundamental idea in software engineering, which is modularity."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argc: int, argv: list) -> int:\n",
    "\n",
    "    agent = BreastCancerLRAgent(CONFIG)\n",
    "    agent.run()\n",
    "    agent.finalize()\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}